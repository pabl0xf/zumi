{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ZumiDemoClassifier.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RobolinkInc/zumi/blob/master/ZumiDrawingClassifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "PESAbvqxd4m_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Landmark Classifier"
      ]
    },
    {
      "metadata": {
        "id": "Spv2QIAQxiOD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# mount Google Drive for loading/uploading\n",
        "# this cell only needs to be ran once per session\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Myfpe6MqltQb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# import modules\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.layers import Activation, Dropout, Flatten, Dense, LeakyReLU\n",
        "from keras import backend as K\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy\n",
        "import cv2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wEstqYUMBjVO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Setting Initial Parameters"
      ]
    },
    {
      "metadata": {
        "id": "gqQoS1FGoCun",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# define image width and height\n",
        "img_width, img_height = 64, 36\n",
        "\n",
        "# define training and validation image directories\n",
        "# directories must be arranged like so:\n",
        "#\n",
        "# train_data_dir/\n",
        "#     classA/\n",
        "#         classA0.png\n",
        "#         ...\n",
        "#         imageA1000.png\n",
        "#     classB/\n",
        "#         classB0.png\n",
        "#         ...\n",
        "#         classB1000.png\n",
        "#\n",
        "# validation_data_dir/\n",
        "#     classA/\n",
        "#         classA0.png\n",
        "#         ...\n",
        "#         imageA100.png\n",
        "#     classB/\n",
        "#         classB0.png\n",
        "#         ...\n",
        "#         classB100.png\n",
        "\n",
        "train_data_dir = '/content/drive/My Drive/MiniTest/'\n",
        "validation_data_dir = '/content/drive/My Drive/Validation/'\n",
        "\n",
        "# define model parameters\n",
        "# nb_train_samples = Sum of all images in training image directory\n",
        "# nb_validation_samples = Sum of all images in validation image directory\n",
        "# epochs = Number of times you want to train the model. More epochs = better accuracy (+), longer training time (-), higher risk of overfitting (--)\n",
        "# batch_size = Number of images that are grouped together for analysis. (nb_train_samples + nb_validation samples) % batch_size MUST equal 0\n",
        "#                 Larger batch_size = better accuracy (+), exponentially larger model size (--)\n",
        "\n",
        "nb_train_samples = 60\n",
        "nb_validation_samples = 60\n",
        "epochs = 30\n",
        "batch_size = 6\n",
        "\n",
        "if K.image_data_format() == 'channels_first':\n",
        "    input_shape = (3, img_width, img_height)\n",
        "else:\n",
        "    input_shape = (img_width, img_height, 3)\n",
        "\n",
        "# define checkpoint parameters\n",
        "# currently, the weights from the most accuracte model are saved to filepath\n",
        "filepath='/content/drive/My Drive/weights-12-3-18.hdf5'\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=True, save_best_only=True, save_weights_only=True, mode='auto', period=1)\n",
        "callbacks_list = [checkpoint]\n",
        "\n",
        "# generate a random number with a seed\n",
        "# only necessary if the neural network architecture uses Dropout()\n",
        "seed = 7\n",
        "numpy.random.seed(seed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "djkaahzzBrCA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Neural Network Architecture"
      ]
    },
    {
      "metadata": {
        "id": "OnbSLsmOoFNk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# apply each action to the model in a sequence\n",
        "model = Sequential()\n",
        "\n",
        "# these cannot be explained in one line. Use an online reference\n",
        "model.add(Conv2D(32, (3, 3), input_shape=input_shape))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(32, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64))\n",
        "model.add(Dropout(0.6, noise_shape=None, seed=seed))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "# change x of Dense(x) to match number of classes\n",
        "model.add(Dense(2))\n",
        "# model.add(Dropout(0.5, noise_shape=None, seed=seed))\n",
        "\n",
        "# if you have 2 classes, use 'sigmoid'. Otherwise, use 'softmax'\n",
        "model.add(Activation('sigmoid'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kjO2yxjvoG7M",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jvaQRG4bB0bO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Data Augmentation\n",
        "Increase the number of training images"
      ]
    },
    {
      "metadata": {
        "id": "JVvSizzioVau",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# train_datagen = imageDataGenerator(\n",
        "#     rescale = normalize image\n",
        "#     shear range = randomly rotate image\n",
        "#     zoom range = randomly zoom/crop image\n",
        "#     horizontal_flip = randomly flip the image horizontally\n",
        "#     )\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1. / 255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=False)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "    validation_data_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Qqp7aRmwB9Eu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Training\n",
        "\"acc\" is the accuracy on the training data,\n",
        "\"val_acc\" is the accuracy on the testing data"
      ]
    },
    {
      "metadata": {
        "id": "6_3O3UN_oXE1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# generate model and graph\n",
        "history = model.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch=nb_train_samples // batch_size,\n",
        "    epochs=epochs,\n",
        "    callbacks=callbacks_list,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=nb_validation_samples // batch_size\n",
        "    )\n",
        "\n",
        "print(history.history.keys())\n",
        "\n",
        "# summarize history for accuracy\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# Notes on reading the graph:\n",
        "#     -For the accuracy graph, higher is better. For loss, lower is better\n",
        "#     -Ideally, the lines should converge. If the lines start to diverge, that means you are underfitting/overfitting and need to either adjust\n",
        "#         the model architecture or lower the number of epochs\n",
        "#     -If the lines flatten out, that means that the time spent running additional epochs is being wasted"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wg84L4yRB7-t",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Prediction\n",
        "This prints the Neural Network's best guess of an image"
      ]
    },
    {
      "metadata": {
        "id": "meDah4mUuKf5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.image import img_to_array, load_img\n",
        "\n",
        "# imgName = the name sans file extension\n",
        "# imgSrc = the directory of the file\n",
        "imgName = 'Test'\n",
        "imgSrc = '/content/drive/My Drive/'\n",
        "\n",
        "imgSrc = imgSrc + imgName + '.png'\n",
        "img = load_img(imgSrc,False,target_size=(img_width,img_height))\n",
        "x = img_to_array(img)\n",
        "maximum = x.max()\n",
        "if maximum > 0:\n",
        "  scaledValue = 255.0/maximum\n",
        "  x *= scaledValue\n",
        "x = numpy.expand_dims(x, axis=0)\n",
        "pred = model.predict(x)\n",
        "print(pred)\n",
        "\n",
        "# Notes on reading the result:\n",
        "#     -Each number in the array represents the probability of the image belonging to a particular class, with a value from 0-1\n",
        "#     -The classes are arranged in alphabetical order, so if you had 2 classes \"cat\" and \"dog\", \"cat\" would be represented by the first element"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
