{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "deOqgRg7j02G"
   },
   "source": [
    "#\"Will It Learn?\" - Word Jumble\n",
    "Will a simple convolution network learn to unscramble a word? Let's make this hard and give it only pixels.\n",
    "\n",
    "###First we will create some functions to draw scrambled word:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zm1Q7JMFG2ph"
   },
   "outputs": [],
   "source": [
    "#This is a code cell. Click on the cell to make it active. \n",
    "#Then click on the left corner arrow in a circle button to run it. Or use the keyboard shortcut ctlr+enter.\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "%matplotlib inline\n",
    "\n",
    "#We will give a single tensor with each channel the board state\n",
    "word = \"jumble\"\n",
    "img_shape = (24,60,3)\n",
    "\n",
    "def img_word(img_shape, word):\n",
    "  w = img_shape[1]\n",
    "  h = img_shape[0]\n",
    "  img = Image.new('RGB', size=(w, h))\n",
    "  draw = ImageDraw.Draw(img)\n",
    "  draw.text((10, h/2 - 5), word)\n",
    "  \n",
    "  return img\n",
    "    \n",
    "img = img_word(img_shape, word)\n",
    "plt.axis('off')\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "\n",
    "#This should show and image of the word jumble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NkExLIg-f6a7"
   },
   "source": [
    "##Next we will create some routines to scramble words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5AilCGMgdkzK"
   },
   "outputs": [],
   "source": [
    "from random import shuffle, randint\n",
    "import numpy as np\n",
    "\n",
    "def scramble(word):\n",
    "  letters = []\n",
    "  for l in word:\n",
    "    letters.append(l)\n",
    "  shuffle(letters)\n",
    "  return ''.join(letters)\n",
    "\n",
    "six_letter_words = ['jumble', 'puzzle', 'lizard', 'wonder', 'object', 'zombie', 'quiver', 'jungle', 'pickup', 'chunky', 'aliens', 'amazon', 'animal',\n",
    "                   'barely', 'burley', 'bobble', 'wildly', 'wicked', 'buying', 'cactus', 'chatty', 'charms', 'charge', 'champs', 'change', 'chewed',\n",
    "                   'dangle', 'decide', 'deluxe', 'dazzle', 'defeat', 'deduce']\n",
    "\n",
    "print('We have', len(six_letter_words), 'six letter words')\n",
    "\n",
    "def get_data(words, image_shape):\n",
    "  iW = randint(0, len(words)-1)\n",
    "  word = words[iW]\n",
    "  scrambled = scramble(word)\n",
    "  img = img_word(image_shape, scrambled)\n",
    "  label = np.zeros(len(words))\n",
    "  label[iW] = 1.0\n",
    "  return np.array(img) / 255.0, label, word\n",
    "\n",
    "img, label, word = get_data(six_letter_words, img_shape)\n",
    "plt.axis('off')\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "print(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "srgX2P6qoIcs"
   },
   "source": [
    "##What do you think?\n",
    "Will this somewhat simple network accomplish the task of learning which of the ten words was chosen and then scrambled, given only the pizels?\n",
    "\n",
    "\n",
    "Let's find out...\n",
    "\n",
    "First let's make sure you are using the GPU. Run the cell bellow to double check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UQYqy0K023PP"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "tf.test.gpu_device_name()\n",
    "#if you see something like '/device:GPU:0' then the gpu accelerated learning will be enabled. if not, cpu will work, just slower."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dxBPjjT0rt4h"
   },
   "source": [
    "##Our Neural Network\n",
    "\n",
    "Here's what our network will look like. Pretty straight foward, 4 layers of convolutions. 64 filters per layer. A 3x3 kernel used in each. With relu activation in each. \n",
    "\n",
    "We will give it all the images planes stacked into one image. We will ask it to activate one of four neurons to represent which corner it thinks the circle is hidding at the end.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sf9j7zQt4ugi"
   },
   "outputs": [],
   "source": [
    "#Let's define a pretty straight forward conv neural network. It will have about 200K params, given the input image dimension of 24 x 60\n",
    "import keras\n",
    "from keras.layers import Flatten, Conv2D, Dense\n",
    "\n",
    "num_words = len(six_letter_words)\n",
    "img = keras.Input(shape=img_shape)\n",
    "\n",
    "x = img\n",
    "x = Conv2D(64, (3, 3), strides=(1,1), activation=\"relu\")(x)\n",
    "x = Conv2D(64, (3, 3), strides=(1,1), activation=\"relu\")(x)\n",
    "x = Conv2D(64, (3, 3), strides=(1,1), activation=\"relu\")(x)\n",
    "x = Conv2D(64, (3, 3), strides=(1,1), activation=\"relu\")(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(100, activation='relu')(x)\n",
    "x = Dense(num_words, activation='softmax')(x)\n",
    "\n",
    "model = keras.Model(img, x)\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"acc\"])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "114nT-qoj4L3"
   },
   "source": [
    "###Now let's start the training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K3L0t5j-wY7j"
   },
   "outputs": [],
   "source": [
    "# Here's function that will generate a numpy array of images and moves for our NN to train on\n",
    "def generator(img_shape, batch_size, words):\n",
    "  while True:\n",
    "    X = []\n",
    "    y = []\n",
    "    for i in range(batch_size):\n",
    "      img, label, word = get_data(words, img_shape)\n",
    "      X.append(img)\n",
    "      y.append(label)\n",
    "    yield np.array(X), np.array(y)\n",
    "    \n",
    "    \n",
    "#Now let's start the training.\n",
    "batch_size = 64\n",
    "steps_per_epoch = 128\n",
    "epochs = 2\n",
    "\n",
    "train_gen = generator(img_shape, batch_size, six_letter_words)\n",
    "\n",
    "model.fit_generator(train_gen, \n",
    "                    steps_per_epoch=steps_per_epoch, \n",
    "                    epochs=epochs, \n",
    "                    verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wU_xaZz0O54K"
   },
   "outputs": [],
   "source": [
    "#Now let's create a new image and see how it does.\n",
    "#Run this code cell multiple times to get a feeling about how it handles different cases.\n",
    "\n",
    "img, label, word = get_data(six_letter_words, img_shape)\n",
    "res = model.predict(img[None, :, :, :])\n",
    "print(\"raw prediction: \", res[0])\n",
    "iPred = np.argmax(res[0])\n",
    "print(\"Predicts:\", six_letter_words[iPred], \"confidence\", res[0][iPred])\n",
    "print(\"Answer:\", word)\n",
    "\n",
    "plt.axis('off')\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9T8uoyjCsQkK"
   },
   "source": [
    "#So What's Your Verdict?\n",
    "###Do you think this learned to unscramble the letters?\n",
    "\n",
    "I don't know why, but I thought this would be a challenge. The fact that I struggle to unscramble these words only underscores my amazement at how quickly and effortlessly it appears to have mastered this. \n",
    "\n",
    "\n",
    "###Note: \n",
    "this wasn't working until I normalized the channel images between 0-1\n",
    "\n",
    "#Further thought..\n",
    "\n",
    "How would this do against a much larger dataset of words?\n",
    "\n",
    "###What tests could you devise to disambiguiate whether it had simply 'memorized' the world state?\n",
    "\n",
    "Could we restucture this to output a vector 6x27 with one hot active for each letter? Would that make it easier or harder?\n",
    "\n",
    "I decided to try. Take a look [here at part 2](https://colab.research.google.com/drive/1qjtyWfpHIn45yOrmDwNIC68p8SaqsP29) if you are curious."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1XY0kIvfdV_a"
   },
   "source": [
    "#Episodes Links:\n",
    "\n",
    "[Will It Learn? - S01E01 Circle Count](https://drive.google.com/open?id=11EiFFa-imh5MNEPJZuqgqJAwLYHhP3gG)\n",
    "\n",
    "[Will It Learn? - S01E02 Tic Tace Toe](https://drive.google.com/open?id=1PKosDR9wcgPaF2-BYMSZiu2nW03COxma)\n",
    "\n",
    "[Will It Learn? - S01E03 : Shell Game](https://drive.google.com/open?id=163iv-LaidgxiU3tT_RcLCT_K1HOdagMu)\n",
    "\n",
    "[Will It Learn? - S01E04 : Word Jumble](https://drive.google.com/open?id=19ENSHOC-TEyDqZ-_47QhSHHxhUAuDEoA)\n",
    "\n",
    "[Will It Learn? - S01E05 : Mazes](https://drive.google.com/open?id=1qdYWNwrmYAtFsayzoxPuuGAE1RTKt1ia)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Will It Learn? S01E04 Word Jumble.ipynb",
   "private_outputs": true,
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
